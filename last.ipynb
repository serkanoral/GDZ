{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    smap = np.zeros(len(y_true))\n",
    "    \n",
    "    num = np.abs(y_true - y_pred)\n",
    "    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n",
    "    \n",
    "    pos_ind = (y_true!=0)|(y_pred!=0)\n",
    "    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n",
    "    \n",
    "    return 100 * np.mean(smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('train.csv', parse_dates=['first_day_of_month'],usecols =lambda x: x != 'active')\n",
    "test = pd.read_csv('test.csv', parse_dates=['first_day_of_month'])\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(train[['cfips', 'county' , 'state']].drop_duplicates(), on = ['cfips'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122265 entries, 0 to 122264\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   row_id                 122265 non-null  object        \n",
      " 1   cfips                  122265 non-null  int64         \n",
      " 2   county                 122265 non-null  object        \n",
      " 3   state                  122265 non-null  object        \n",
      " 4   first_day_of_month     122265 non-null  datetime64[ns]\n",
      " 5   microbusiness_density  122265 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25080 entries, 0 to 25079\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   row_id              25080 non-null  object        \n",
      " 1   cfips               25080 non-null  int64         \n",
      " 2   first_day_of_month  25080 non-null  datetime64[ns]\n",
      " 3   county              25080 non-null  object        \n",
      " 4   state               25080 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train['first_day_of_month'].dt.month\n",
    "train['year'] = train['first_day_of_month'].dt.year\n",
    "test['month'] = test['first_day_of_month'].dt.month\n",
    "test['year'] = test['first_day_of_month'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "3  1001_2019-11-01   1001  Autauga County  Alabama         2019-11-01   \n",
       "4  1001_2019-12-01   1001  Autauga County  Alabama         2019-12-01   \n",
       "\n",
       "   microbusiness_density  month  year  \n",
       "0               3.007682      8  2019  \n",
       "1               2.884870      9  2019  \n",
       "2               3.055843     10  2019  \n",
       "3               2.993233     11  2019  \n",
       "4               2.993233     12  2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2022-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003_2022-11-01</td>\n",
       "      <td>1003</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005_2022-11-01</td>\n",
       "      <td>1005</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007_2022-11-01</td>\n",
       "      <td>1007</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009_2022-11-01</td>\n",
       "      <td>1009</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips first_day_of_month          county    state  month  \\\n",
       "0  1001_2022-11-01   1001         2022-11-01  Autauga County  Alabama     11   \n",
       "1  1003_2022-11-01   1003         2022-11-01  Baldwin County  Alabama     11   \n",
       "2  1005_2022-11-01   1005         2022-11-01  Barbour County  Alabama     11   \n",
       "3  1007_2022-11-01   1007         2022-11-01     Bibb County  Alabama     11   \n",
       "4  1009_2022-11-01   1009         2022-11-01   Blount County  Alabama     11   \n",
       "\n",
       "   year  \n",
       "0  2022  \n",
       "1  2022  \n",
       "2  2022  \n",
       "3  2022  \n",
       "4  2022  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls = pd.read_csv('archive/bls-emp_by_cfips.csv', parse_dates=['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls['first_day_of_month'] = bls['first_day_of_month'] +pd.DateOffset(years= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls['row_id'] = bls['cfips'].astype(str) + '_' + bls['first_day_of_month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>footnote_codes</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>measure_type</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAUCN010010000000003</td>\n",
       "      <td>1990</td>\n",
       "      <td>M01</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>1001_1991-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAUCN010010000000003</td>\n",
       "      <td>1990</td>\n",
       "      <td>M02</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>1991-02-01</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>1001_1991-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAUCN010010000000003</td>\n",
       "      <td>1990</td>\n",
       "      <td>M03</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>1991-03-01</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>1001_1991-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAUCN010010000000003</td>\n",
       "      <td>1990</td>\n",
       "      <td>M04</td>\n",
       "      <td>6.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>1991-04-01</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>1001_1991-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAUCN010010000000003</td>\n",
       "      <td>1990</td>\n",
       "      <td>M05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>1991-05-01</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>1001_1991-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              series_id  year period  value footnote_codes  cfips  \\\n",
       "0  LAUCN010010000000003  1990    M01    6.5            NaN   1001   \n",
       "1  LAUCN010010000000003  1990    M02    6.5            NaN   1001   \n",
       "2  LAUCN010010000000003  1990    M03    5.7            NaN   1001   \n",
       "3  LAUCN010010000000003  1990    M04    6.6            NaN   1001   \n",
       "4  LAUCN010010000000003  1990    M05    6.0            NaN   1001   \n",
       "\n",
       "  first_day_of_month       measure_type           row_id  \n",
       "0         1991-01-01  Unemployment rate  1001_1991-01-01  \n",
       "1         1991-02-01  Unemployment rate  1001_1991-02-01  \n",
       "2         1991-03-01  Unemployment rate  1001_1991-03-01  \n",
       "3         1991-04-01  Unemployment rate  1001_1991-04-01  \n",
       "4         1991-05-01  Unemployment rate  1001_1991-05-01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1991-01-01 00:00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls.first_day_of_month.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_rate = bls[bls['measure_type'] == 'Unemployment rate']\n",
    "unemp = bls[bls['measure_type'] == 'Unemployment']\n",
    "employment = bls[bls['measure_type'] == 'Employment']\n",
    "lab_force = bls[bls['measure_type'] == 'Labor force']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_rate = unemp_rate[['row_id', 'value']].rename( columns= {'row_id' : 'row_id', 'value' : 'unemp_rate'})\n",
    "unemp = unemp[['row_id', 'value']].rename( columns= {'row_id' : 'row_id', 'value' : 'unemp'})\n",
    "employment = employment[['row_id', 'value']].rename( columns= {'row_id' : 'row_id', 'value' : 'employment'})\n",
    "lab_force = lab_force[['row_id', 'value']].rename( columns= {'row_id' : 'row_id', 'value' : 'lab_force'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.merge(unemp_rate, \n",
    "#            on = 'row_id', how = 'left').merge(unemp, \n",
    "#             on = 'row_id', how = 'left').merge(employment,\n",
    "#             on = 'row_id', how = 'left').merge(lab_force,\n",
    "#             on = 'row_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.merge(unemp_rate, \n",
    "#             on = 'row_id', how = 'left').merge(unemp, \n",
    "#             on = 'row_id', how = 'left').merge(employment,\n",
    "#             on = 'row_id', how = 'left').merge(lab_force,\n",
    "#             on = 'row_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "3  1001_2019-11-01   1001  Autauga County  Alabama         2019-11-01   \n",
       "4  1001_2019-12-01   1001  Autauga County  Alabama         2019-12-01   \n",
       "\n",
       "   microbusiness_density  month  year  \n",
       "0               3.007682      8  2019  \n",
       "1               2.884870      9  2019  \n",
       "2               3.055843     10  2019  \n",
       "3               2.993233     11  2019  \n",
       "4               2.993233     12  2019  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accommodation = pd.read_csv('all_indicators-all_data/accommodation_and_food_services_state_gdp_raw_in_millions.csv', sep= ';')\n",
    "employment = pd.read_csv('all_indicators-all_data/federal_public_employment_raw_in_thousands.csv')\n",
    "gdp = pd.read_csv('all_indicators-all_data/government_state_gdp_raw_in_millions.csv', sep= ';')\n",
    "manufacturing_employment = pd.read_csv('all_indicators-all_data/manufacturing_employment_raw_in_thousands.csv')\n",
    "private_employment = pd.read_csv('all_indicators-all_data/private_employment_raw_in_thousands.csv')\n",
    "public_employment = pd.read_csv('all_indicators-all_data/public_employment_raw_in_thousands.csv')\n",
    "retail_retail_trade_employment = pd.read_csv('all_indicators-all_data/retail_trade_employment_raw_in_thousands.csv')\n",
    "retail_trade_state = pd.read_csv('all_indicators-all_data/retail_trade_state_gdp_raw_in_millions.csv', sep= ';')\n",
    "state_and_local_public_education = pd.read_csv('all_indicators-all_data/state_and_local_public_education_employment_raw_in_thousands.csv')\n",
    "state_and_local_public_employment = pd.read_csv('all_indicators-all_data/state_and_local_public_employment_raw_in_thousands.csv')\n",
    "state_gdp = pd.read_csv('all_indicators-all_data/state_gdp_raw_in_millions.csv', sep= ';')\n",
    "total_employment = pd.read_csv('all_indicators-all_data/total_employment_raw_in_thousands.csv')\n",
    "unemployment_rate = pd.read_csv('all_indicators-all_data/unemployment_rate_raw.csv')\n",
    "weekly_earnings = pd.read_csv('all_indicators-all_data/weekly_earnings_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_earnings.rename(columns={'Geography':'state'}, inplace= True)\n",
    "unemployment_rate.rename(columns={'Geography':'state'}, inplace= True)\n",
    "total_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "state_gdp.rename(columns={'Geography':'state'}, inplace= True)\n",
    "state_and_local_public_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "state_and_local_public_education.rename(columns={'Geography':'state'}, inplace= True)\n",
    "retail_trade_state.rename(columns={'Geography':'state'}, inplace= True)\n",
    "retail_retail_trade_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "public_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "private_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "manufacturing_employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "gdp.rename(columns={'Geography':'state'}, inplace= True)\n",
    "employment.rename(columns={'Geography':'state'}, inplace= True)\n",
    "accommodation.rename(columns={'Geography':'state'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_earnings_melt =  weekly_earnings.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'weekly_earnings')\n",
    "weekly_earnings_melt['first_day_of_month'] = pd.to_datetime(weekly_earnings_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accommodation_melt =  accommodation.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'accommodation')\n",
    "accommodation_melt['first_day_of_month'] = pd.to_datetime(accommodation_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_melt =  employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'employment')\n",
    "employment_melt['first_day_of_month'] = pd.to_datetime(employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_melt =  gdp.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'gdp')\n",
    "gdp_melt['first_day_of_month'] = pd.to_datetime(gdp_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturing_employment_melt =  manufacturing_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'manufacturing_employment')\n",
    "manufacturing_employment_melt['first_day_of_month'] = pd.to_datetime(manufacturing_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_employment_melt =  private_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'private_employment')\n",
    "private_employment_melt['first_day_of_month'] = pd.to_datetime(private_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_employment_melt =  public_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'public_employment')\n",
    "public_employment_melt['first_day_of_month'] = pd.to_datetime(public_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_retail_trade_employment_melt =  retail_retail_trade_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'retail_retail_trade_employment')\n",
    "retail_retail_trade_employment_melt['first_day_of_month'] = pd.to_datetime(retail_retail_trade_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_trade_state_melt =  retail_trade_state.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'retail_trade_state')\n",
    "retail_trade_state_melt['first_day_of_month'] = pd.to_datetime(retail_trade_state_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_and_local_public_education_melt =  state_and_local_public_education.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'state_and_local_public_education')\n",
    "state_and_local_public_education_melt['first_day_of_month'] = pd.to_datetime(state_and_local_public_education_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_and_local_public_employment_melt =  state_and_local_public_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'state_and_local_public_employment')\n",
    "state_and_local_public_employment_melt['first_day_of_month'] = pd.to_datetime(state_and_local_public_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gdp_melt =  state_gdp.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'state_gdp')\n",
    "state_gdp_melt['first_day_of_month'] = pd.to_datetime(state_gdp_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_employment_melt =  total_employment.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'total_employment')\n",
    "total_employment_melt['first_day_of_month'] = pd.to_datetime(total_employment_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_rate_melt =  unemployment_rate.melt(id_vars= 'state',var_name= 'first_day_of_month', \n",
    "                                             value_name= 'unemployment_rate')\n",
    "unemployment_rate_melt['first_day_of_month'] = pd.to_datetime(unemployment_rate_melt['first_day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = accommodation_melt.merge(employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(gdp_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(manufacturing_employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(private_employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(public_employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(retail_retail_trade_employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(retail_trade_state_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(state_gdp_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(total_employment_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(unemployment_rate_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left').merge(weekly_earnings_melt, on = ['state','first_day_of_month'], \n",
    "          how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding one year - lagging\n",
    "data_merged['first_day_of_month'] = data_merged['first_day_of_month'] +pd.DateOffset(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(data_merged, on = ['state', 'first_day_of_month'], \n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(data_merged, on = ['state', 'first_day_of_month'], \n",
    "                  how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('first_day_of_month',  inplace= True)\n",
    "test.set_index('first_day_of_month', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['row_id','county', 'state' ], axis=1, inplace=True)\n",
    "row_id = test['row_id']\n",
    "test.drop(['row_id','county', 'state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 122265 entries, 2019-08-01 to 2022-10-01\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   cfips                           122265 non-null  int64  \n",
      " 1   microbusiness_density           122265 non-null  float64\n",
      " 2   month                           122265 non-null  int64  \n",
      " 3   year                            122265 non-null  int64  \n",
      " 4   accommodation                   122265 non-null  float64\n",
      " 5   employment                      122265 non-null  float64\n",
      " 6   gdp                             122265 non-null  float64\n",
      " 7   manufacturing_employment        122265 non-null  float64\n",
      " 8   private_employment              122265 non-null  float64\n",
      " 9   public_employment               122265 non-null  float64\n",
      " 10  retail_retail_trade_employment  122265 non-null  float64\n",
      " 11  retail_trade_state              122265 non-null  float64\n",
      " 12  state_gdp                       122265 non-null  float64\n",
      " 13  total_employment                122265 non-null  float64\n",
      " 14  unemployment_rate               122265 non-null  float64\n",
      " 15  weekly_earnings                 122265 non-null  float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 15.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cfips'] = train['cfips'].astype('category')\n",
    "test['cfips'] = test['cfips'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 122265 entries, 2019-08-01 to 2022-10-01\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count   Dtype   \n",
      "---  ------                          --------------   -----   \n",
      " 0   cfips                           122265 non-null  category\n",
      " 1   microbusiness_density           122265 non-null  float64 \n",
      " 2   month                           122265 non-null  int64   \n",
      " 3   year                            122265 non-null  int64   \n",
      " 4   accommodation                   122265 non-null  float64 \n",
      " 5   employment                      122265 non-null  float64 \n",
      " 6   gdp                             122265 non-null  float64 \n",
      " 7   manufacturing_employment        122265 non-null  float64 \n",
      " 8   private_employment              122265 non-null  float64 \n",
      " 9   public_employment               122265 non-null  float64 \n",
      " 10  retail_retail_trade_employment  122265 non-null  float64 \n",
      " 11  retail_trade_state              122265 non-null  float64 \n",
      " 12  state_gdp                       122265 non-null  float64 \n",
      " 13  total_employment                122265 non-null  float64 \n",
      " 14  unemployment_rate               122265 non-null  float64 \n",
      " 15  weekly_earnings                 122265 non-null  float64 \n",
      "dtypes: category(1), float64(13), int64(2)\n",
      "memory usage: 15.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('rd', LGBMRegressor())])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),\n",
    "#                      ('scaler', RobustScaler()),('rd', Ridge(alpha=42))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(3)),\n",
    "#                      ('scaler', RobustScaler()),('rd', Ridge(alpha=42))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(3)),\n",
    "#                      ('scaler', RobustScaler()), ('rd', RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10, 100]))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),('lr', LinearRegression())])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),('lr', KernelRidge())])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),('lr', BayesianRidge())])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# y_test_ = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),('lr', RandomForestRegressor())])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(X_test[X_test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "#     y_test = list(y_test)\n",
    "#     y_test_ += list(y_test)\n",
    "# #submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# #pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X.sort_index()\n",
    "#     y.sort_index()\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('lgbm', \n",
    "#             LGBMRegressor(learning_rate= 0.001,n_estimators=1000,objective='mean_squared_error'))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['cfips'] == 1001].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in list(train['cfips'].unique()):\n",
    "    np.random.seed(42)\n",
    "    X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "    y = train[train['cfips'] == i]['microbusiness_density']\n",
    "    X.sort_index(inplace= True)\n",
    "    y.sort_index(inplace= True)\n",
    "    pipe = Pipeline([('impute', KNNImputer()),\n",
    "                     ('pca', PCA(n_components= test[test['cfips'] == i].shape[0])),\n",
    "                     ('rd', Ridge(alpha=100))])\n",
    "    pipe.fit(X, y)\n",
    "    prediction = pipe.predict(test[test['cfips'] == i])\n",
    "    prediction = list(prediction)\n",
    "    y_pred += prediction\n",
    "    \n",
    "submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "#smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(3)),\n",
    "#                      ('scaler', RobustScaler()), ('rd', RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10, 100]))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('poly', PolynomialFeatures(2)),\n",
    "#                      ('rd', RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10, 100]))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('log',FunctionTransformer(np.sqrt)),\n",
    "#                      ('rd', Ridge(alpha=100))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X.sort_index(inplace= True)\n",
    "#     y.sort_index(inplace= True)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),\n",
    "#                      ('rd', Ridge(alpha=100, random_state=42))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X.sort_index(inplace= True)\n",
    "#     y.sort_index(inplace= True)\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),\n",
    "#                      ('rd', RandomForestRegressor(random_state=42))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X.sort_index()\n",
    "#     y.sort_index()\n",
    "#     pipe = Pipeline([('xgb', xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 5, alpha = 10, n_estimators = 10))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "   \n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfips = train[['cfips']]\n",
    "# month = train[['month']]\n",
    "# year = train[['year']]\n",
    "# microbusiness_density = train[['microbusiness_density']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc['2021-01-01':'2021-09-01']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(['cfips','month', 'year','microbusiness_density' ], inplace= True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['cfips'] = cfips\n",
    "# train['month'] = month\n",
    "# train['year'] = year\n",
    "# train['microbusiness_density'] = microbusiness_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    " # annormalities removed\n",
    "# y_pred = []\n",
    "# for i in list(train['cfips'].unique()):\n",
    "#     np.random.seed(42)\n",
    "#     X = train[train['cfips'] == i].drop('microbusiness_density', axis= 1)\n",
    "#     y = train[train['cfips'] == i]['microbusiness_density']\n",
    "#     X.sort_index()\n",
    "#     y.sort_index()\n",
    "#     pipe = Pipeline([('impute', KNNImputer()),('xgb', xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 5, alpha = 10, n_estimators = 10))])\n",
    "#     pipe.fit(X, y)\n",
    "#     prediction = pipe.predict(test[test['cfips'] == i])\n",
    "#     prediction = list(prediction)\n",
    "#     y_pred += prediction\n",
    "   \n",
    "    \n",
    "# submission = pd.DataFrame({'row_id' : row_id.values, 'microbusiness_density' : y_pred})\n",
    "# #smape(np.array(y_test_) ,np.array(y_pred) )\n",
    "# pd.DataFrame.to_csv(submission, 'submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1824d2fb8a48665db480c4b55814db7773f558a7ae57d4d77d082fe74fb9f1fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
